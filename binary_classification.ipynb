{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/LarsBentsen/CourseDSAIStatisticalLearning/blob/main/binary_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIDS Virus infection classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score, roc_auc_score, recall_score, RocCurveDisplay\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the AIDS classification dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://github.com/LarsBentsen/CourseDSAIStatisticalLearning/blob/main/data/AIDS_Classification.csv?raw=true')\n",
    "print(\"number of rows: \", df.shape[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and test set\n",
    "\n",
    "np.random.seed(666)\n",
    "test_indxs = np.random.choice(np.arange(df.shape[0]), size=df.shape[0] // 5, replace=False)\n",
    "df_test = df.iloc[test_indxs]\n",
    "df = df.drop(test_indxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the response: infected\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.histplot(x=df['infected'], bins=10, palette='viridis', kde=True)\n",
    "plt.title(\"The distribution of response: Infected\")\n",
    "plt.ylabel(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check class imbalance\n",
    "df[df['infected'] == 1].shape[0] / df[df['infected'] == 0].shape[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many option for data pre-processing which will depend on the data and analysis. For training purposes we will skip straight to the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and test set\n",
    "\n",
    "y_train = df['infected']\n",
    "X_train = df.drop('infected',axis = 1)\n",
    "\n",
    "y_test = df_test['infected']\n",
    "X_test = df_test.drop('infected',axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rfc = RandomForestClassifier() # default hyperparameter values\n",
    "model = rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest has many hyperparameters suitable for tuning. You can check them out [here](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier). For imbalanced binary classification, especially the parameter class_weight can be of interest, which are the weights associated with the classes. If not given, all classes are supposed to have weight one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuarcy = accuracy_score(y_test,y_pred)\n",
    "bacc = balanced_accuracy_score(y_test,y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "sensitivity =  recall_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuarcy)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Balanced accuracy:\", bacc)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "# confusion matrix\n",
    "print(confusion_matrix(y_pred, y_test))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC curve\n",
    "RocCurveDisplay.from_predictions(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "\n",
    "clf = xgb.XGBClassifier() # default hyperparameter values\n",
    "model = clf.fit(X_train, y_train, eval_set=[(X_test, y_test)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost has many hyperparameters suitable for tuning. You can check them out [here](https://xgboost.readthedocs.io/en/stable/parameter.html). For imbalanced binary classification, especially the parameter scale_pos_weight can be of interest, which controls the balance of positive and negative weights. The default value is 1, while a typical value to consider is the sum(negative instances) / sum(positive instances)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuarcy = accuracy_score(y_test,y_pred)\n",
    "bacc = balanced_accuracy_score(y_test,y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "sensitivity =  recall_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuarcy)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Balanced accuracy:\", bacc)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "# confusion matrix\n",
    "print(confusion_matrix(y_pred, y_test))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC curve\n",
    "RocCurveDisplay.from_predictions(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Minority Over-sampling Technique (SMOTE)\n",
    "To tackle imbalanced datasets, read the article [here](https://arxiv.org/pdf/1106.1813)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE tp the dataset\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rfc = RandomForestClassifier() # default hyperparameter values\n",
    "model = rfc.fit(X_res,y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuarcy = accuracy_score(y_test,y_pred)\n",
    "bacc = balanced_accuracy_score(y_test,y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "sensitivity =  recall_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuarcy)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Balanced accuracy:\", bacc)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "# confusion matrix\n",
    "print(confusion_matrix(y_pred, y_test))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC curve\n",
    "RocCurveDisplay.from_predictions(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "\n",
    "clf = xgb.XGBClassifier() # default hyperparameter values\n",
    "model = clf.fit(X_res, y_res, eval_set=[(X_test, y_test)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuarcy = accuracy_score(y_test,y_pred)\n",
    "bacc = balanced_accuracy_score(y_test,y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "sensitivity =  recall_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuarcy)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Balanced accuracy:\", bacc)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "# confusion matrix\n",
    "print(confusion_matrix(y_pred, y_test))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC curve\n",
    "RocCurveDisplay.from_predictions(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
